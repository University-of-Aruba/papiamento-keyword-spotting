{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb402292",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fbea2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import DatasetFolder\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700e5742",
   "metadata": {},
   "source": [
    "# Download and Extract The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18a1e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the zip file from the provided URL and extract it to the specified directory\n",
    "def download_and_extract_dataset(url: str, compressed_file_name: str, extract_to: str, root_data_folder: str, overwrite=False, extract_only=True):\n",
    "    \"\"\"Downloads a zip file from the given URL and extracts it to the specified directory.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the zip file to download.\n",
    "        compressed_file_name (str): The name of the zip file to be saved locally.\n",
    "        extract_to (str): The directory where the contents should be extracted.\n",
    "        root_data_folder (str): The root folder inside the zip file to extract.\n",
    "        overwrite (bool): If True, will overwrite the existing files in the directory.\n",
    "        extract_only (bool): If True, will only extract the contents if the directory is empty\n",
    "        or does not exist.\n",
    "    \"\"\"\n",
    "    import requests\n",
    "    from zipfile import ZipFile\n",
    "    from io import BytesIO\n",
    "\n",
    "    # Check that there are a total of 16766 files in 7 folders (classes)\n",
    "    def verify_dataset_files(directory):\n",
    "        exp_file_count = 16766\n",
    "        exp_folder_count = 7\n",
    "        total_files = 0\n",
    "        total_dirs = 0\n",
    "        for _, dirs, files in os.walk(directory):\n",
    "            total_files += len(files)\n",
    "            total_dirs += len(dirs)\n",
    "        intact = total_files == exp_file_count and total_dirs == exp_folder_count\n",
    "        print(f\"Expected {exp_file_count} files and {exp_folder_count} folders.\")\n",
    "        print(f\"Found {total_files} files and {total_dirs} folders.\")\n",
    "        return intact\n",
    "\n",
    "    zip_file_name = compressed_file_name\n",
    "    zip_file_path = os.path.join(os.getcwd(), zip_file_name)\n",
    "    # Ensure the extract_to directory exists\n",
    "    if not os.path.exists(extract_to):\n",
    "        os.makedirs(extract_to)\n",
    "\n",
    "    # If extract_only is False, we will always download the dataset\n",
    "    if not extract_only:\n",
    "        # Show download progress and save to zip_file_name\n",
    "        with requests.get(url, stream=True) as response:\n",
    "            if response.status_code == 200:\n",
    "                total_length = int(response.headers.get('content-length', 0))\n",
    "                chunk_size = 8192\n",
    "                downloaded = 0\n",
    "                with open(zip_file_name, 'wb') as f:\n",
    "                    print(\"Downloading dataset...\")\n",
    "                    for chunk in response.iter_content(chunk_size=chunk_size):\n",
    "                        if chunk:\n",
    "                            f.write(chunk)\n",
    "                            downloaded += len(chunk)\n",
    "                            done = int(50 * downloaded / total_length) if total_length else 0\n",
    "                            sys.stdout.write('\\r[{}{}] {:.2f}%'.format(\n",
    "                                '=' * done, ' ' * (50 - done),\n",
    "                                100 * downloaded / total_length if total_length else 0))\n",
    "                            sys.stdout.flush()\n",
    "                    print()  # Newline after progress bar\n",
    "                with open(zip_file_name, 'rb') as f:\n",
    "                    zip_file = ZipFile(f)\n",
    "            else:\n",
    "                print(f\"Failed to download dataset. Status code: {response.status_code}\")\n",
    "        \n",
    "    # If overwrite is True, we extract the existing zip file\n",
    "    if overwrite:\n",
    "        # Check if the zip file already exists\n",
    "        if os.path.exists(zip_file_path):\n",
    "            try:\n",
    "                print(f\"Using existing zip file: {zip_file_path}\")\n",
    "                with ZipFile(zip_file_path, 'r') as zip_file:\n",
    "                    print(f\"Extracting zip file to {extract_to}...\")\n",
    "                    zip_file.extractall(path=extract_to)\n",
    "                print(\"Extraction complete.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to extract zip file: {e}\")\n",
    "                print(\"The zip file may be corrupted. Please delete it and re-download.\")\n",
    "                return\n",
    "        else:\n",
    "            print(f\"The zip file does not exist at {zip_file_path}. Set extract_only=False to download it.\")\n",
    "            return\n",
    "\n",
    "    # Check if the dataset is already extracted and intact\n",
    "    print(f\"Checking if existing dataset is intact...\")\n",
    "    if verify_dataset_files(os.path.join(extract_to, root_data_folder)):\n",
    "        print(f\"Dataset is intact.\")\n",
    "    else:\n",
    "        print(f\"Dataset is incomplete or corrupted. Download again.\")\n",
    "\n",
    "download_and_extract_dataset(\n",
    "    url=\"https://some_link_to_dataset.zip\",\n",
    "    compressed_file_name=\"stft_spectrograms.zip\",\n",
    "    extract_to=\"data_directory\",\n",
    "    root_data_folder=\"stft_spectrograms\",\n",
    "    overwrite=False,\n",
    "    extract_only=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
